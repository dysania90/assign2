date wed 20 nov 1996 221554 gmt  server ncsa151  lastmodified thu 07 nov 1996 221429 gmt  contenttype texthtml  contentlength 21116     cps 370  fall 1996                                         fall 1996             planning under uncertainty                 background    grading    outline    projects        jump to current place in outline      evolving syllabus       background   this seminar will introduce students to an exciting area of research that draws upon results from operations research markov decision processes machine learning reinforcement learning and traditional ai planning to attack problems with great scientific and commercial potential  we will read and discuss a handful of recent papers that will give students an appreciation for the state of the art  students will undertake a group research project to solidify their understanding of the basic concepts and perhaps to contribute to the field     i will make a number of presentations to introduce students to the background material necessary to read the research papersonly undergraduatelevel computer science knowledge and basic probability theory and calculus will be assumed  i think there are useful contributions to be made by researchers in ai algorithms complexity numerical methods and systems and i think people in all these areas would find some useful information in the seminar  everyones welcome   instructor   michael l littman  office d209 lsrc phone 6606537 email mlittmancsdukeedu office hours tba    description   research in planning making a sequence of choices to achieve some goal has been a mainstay of artificial intelligence ai for many years  traditionally the decisionmaking models that have been studied admit no uncertainty whatsoeverevery aspect of the world that is relevant to the generation and execution of a plan is known in advance  in contrast work in operations research or has focussed on the uncertainty of actions but uses an impoverished representation for specifying planning problems      the purpose of this seminar is to explore some middle ground between these two wellstudied extremes with the hope of understanding how we might create systems that can reason efficiently about plans in complex uncertain worlds  we will review the foundational results from ai and or and read a series of papers written over the last few years that have begun to bridge the gap   philosophy  there are basically two or three papers on different approaches to the same basic problem that id like people to read and understand  these papers are quite recent and represent active areas of research that have been maturing quite quickly over the last few years  as a result to get a deep appreciation for this work we will need to read a number of papers that introduce the necessary background     my approach to organizing the seminar will be to try to keep the assigned reading to a minimum and to ask students to concentrate on understanding the state of the field and on identifying the important open research questions   prerequisites  the seminar should be accessible to any advanced computer science student  my goal is to introduce critical background material as the need arises     nonetheless we need some common ground to begin  i will assume that students are familiar with programming any language algorithm analysis big o notation calculus derivates of multivariate functions and probability theory conditional probabilities  postrequisites  in addition to exploring the question of how to create plans that are effective in uncertain environments there are a number of other important topics that students will learn about in this seminar students will be exposed to markov decision processes dynamic programming linear programming temporal difference learning supervised function approximation gradient descent and neural networks strips rules and partial order planning     grading   the grading policy is designed to stimulate students to think about some of the important issues in this area  class grade will be based on    class participation 25  short homework assignments 25 and  a final project 50      outline  organization meeting  on thursday september 5th d344 230300 well get together to discuss the best time to schedule the class  if you cant make the meeting please send me email mlittmancsdukeedu   introduction  what is planning  what is uncertainty  what are some applications of planning under uncertainty  ill lay out the space of issues and describe the part of the space well explore      michael lederman littman  algorithms for sequential decision making  phd dissertation and technical report cs9609 brown university department of computer science providence ri march 1996  chapter 1 introduction  local postscript local bibliography postscript   markov decision processes  ill introduce the mdp model which is a formal specification for the particular problem we will be examining  ill describe the fundamental concepts states actions transitions rewards discounting horizons results existence and dominance of optimal value function optimal greedy policies and the algorithms value iteration policy iteration modified policy iteration linear programming     in a sense these algorithms completely solve the problem of planning under uncertainty  the rest of the seminar is concerned with solving mdps more efficiently by exploiting additional structure present in some instances      michael l littman thomas l dean and leslie pack kaelbling  on the complexity of solving markov decision problems  in proceedings of the eleventh annual conference on uncertainty in artificial intelligence uai95 montreal quebec canada 1995 postscript     homework represent a complex domain as an mdp     slides postscript      accelerating solutions to mdps  one class of algorithms for solving mdps more quickly restricts valueiteration updates to states that are likely to benefit from additional computational resources     prioritized sweeping uses a heuristic for measuring when updating the value of a state is likely to be important for computing an approximately optimal solution quickly      andrew w moore and christopher g atkeson  prioritized sweeping reinforcement learning with less data and less real time machine learning 13103 1993  compressed postscript     realtime dynamic programming attempts to find a good approximate policy quickly by focussing updates on states that are likely to be visited       andrew g barto s j bradtke and satinder p singh learning to act using realtime dynamic programming artificial intelligence 72181138 1995  compressed postscript     another approach is to explicitly produce a good partial policy by identifying states that are likely to be visited and solving a smaller mdp      jonathan tash and stuart russell control strategies for a stochastic planner  in proceedings of the 12th national conference on artificial intelligence 10791085 1994  postscript     slides postscript      value function approximation  the above approaches represent states as being completely unrelated objects  in many domains states can be described in such a way that similar states from a policy or value standpoint have similar representations  for example any attempt to create a transition function for the game of backgammon would likely make use of a boardbased representation of states     this insight can be exploited by exchanging the classical tablebased method for representating value functions to one that uses a function approximator for example a neural net to map state description vectors to values  a wildly successful example of this is tdgammon this work makes use of several important background ideas including gradient descent and temporal difference learning that we will need to look at as well       richard s sutton  learning to predict by the method of temporal differences machine learning 31944 1988  postscript      gerald tesauro temporal difference learning and tdgammon communications of the acm 3835868 1995 html     slides postscript     another interesting application of td lambda and neural networks applied to mdplike problems is crites and bartos elevator controller      robert h crites and andrew g barto  improving elevator performance using reinforcement learning  in d s touretzky m c mozer and m e hasselmo editors advances in neural information processing systems 8 1996  the mit press compressed postscript     an even simpler and similarly successful example for cellular phone channel assignments is based on td0 and a linear function approximator      satinder singh and dimitri bertsekas reinforcement learning for dynamic channel allocation in cellular telephone systems  to appear in advances in neural information processing systems 9 1997  the mit press  postscript     tesauros work is difficult to generalize because it simultaneously addresses many unsolved problems  more recent work has begun to tease apart the effect of using function approximation in dynamic programming from the use of the temporal difference algorithm      justin a boyan and andrew w moore generalization in reinforcement learning safely approximating the value function  in g tesauro d s touretzky and t k leen editors advances in neural information processing systems 7 1995  the mit press  compressed postscript recent workshop on value function approximation     these results were not convincing to everyone      richard s sutton generalization in reinforcement learning successful examples using sparse coarse coding  in advances in neural information processing systems 8 1996  the mit press postscript     slides postscript     some of the most interesting recent work has concerned theoretical results on when function approximation will and will not result in a convergent algorithm  results exist concerning gradient descent methods and averaging methods       leemon baird  residual algorithms reinforcement learning with function approximation  in armand prieditis and stuart russell editors proceedings of the twelfth international conference on machine learning 3037 1995  morgan kaufmann compressed postscript html      geoffrey j gordon  stable function approximation in dynamic programming  in armand prieditis and stuart russell editors proceedings of the twelfth international conference on machine learning 261268  1995  morgan kaufmann compressed postscript      john n tsitsiklis and benjamin van roy  featurebased methods for large scale dynamic programming  machine learning 22123 5994 1996 local postscript     homework propose a research project  stochastic planning  the work on function approximation attempts to exploit structure in the state space but treats actions as black box tranformations from states to distributions over states  a promising alternative is to use symbolic descriptions of the actions to reason about entire classes of statetostate transitions all at once  this is the approach taken in ai planning      david mcallester and david rosenblitt  systematic nonlinear planning  in proceedings of the 9th national conference on artificial intelligence 1991  postscript lisp code     in the last two years planning algorithms have been proposed that differ substantially from the classic planners  although unconventional these planners have been shown empirically to result in much shorter running times up to several orders of magnitude faster  blum and fursts algorithm views planning as a type of graph search while kautz and selman reduce planning to a boolean satisfiability problem      avrim blum and merrick furst  fast planning through planning graph analysis  in proceedings of the 14th international joint conference on artificial intelligence ijcai pages 16361642 1995  extended version in compressed postscript      henry kautz and bart selman  pushing the envelope planning propositional logic and stochastic search  in proceedings of the 13th national conference on artificial intelligence 1996  postscript     slides postscript     in spite of recent algorithmic advances the traditional view of planning ignores uncertainty  uncertainty can be introduced gently by assuming a deterministic domain with some randomness added in      jim blythe  planning with external events  in proceedings of the tenth conference on uncertainty in artificial intelligence 1994  postscript     the buridan system introduces a more general representation for stochastic strips operators and extends partial order planning to stochastic domains  its representation is equivalent in expressiveness to mdps     slides postscript      nicholas kushmerick steve hanks and daniel s weld  an algorithm for probabilistic planning  artificial intelligence 7612 239286 1995 compressed postscript     the buridan system has been expanded so that the plan representation is more powerful though less powerful than a policylike representation      denise draper steve hanks and dan weld  probabilistic planning with information gathering and contingent execution technical report 931204 university of washington department of computer science seattle wa december 1993 compressed postscript     slides postscript     an area of intense interest but remarkably little work is combining direct manipulation of stripstype actions with a dynamicprogrammingbased algorithm  several papers adopt the view that function approximation is a form of abstraction the form of which can be derived automatically from a propositional representation of the planning problem      richard dearden and craig boutilier  abstraction and approximate decision theoretic planning  to appear in artificial intelligence postscript      craig boutilier richard dearden and moises goldszmidt  exploiting structure in policy construction  to appear in proceedings of the international joint conference on artificial intelligence 1995 postscript      craig boutilier and richard dearden  approximating value trees in structured dynamic programming  to appear in proceedings of the thirteenth international conference on machine learning 1996  postscript  slides postscript     summary slides postscript       next well deal with partially observable markov decision processes and how to solve them  advanced topics  if we make unexpectedly fast progress through the core topics there are a number of interesting issues we could explore including hierarchical solutions to mdps partially observable mdps solving games     here are some papers ive recently found that might be useful to discuss  the first gives a notation for representing multiplayer games of incomplete information that might be useful in defining a similar notation for mdps  the second describes how to solve very large and even continuous state mdps efficiently using linear programming      daphne koller and avi pfeffer  representations and solutions for gametheoretic problems  preliminary version appeared in proceedings of the 14th international joint conference on artificial intelligence ijcai montreal canada august 1995 pages 11851192 postscript      michael trick and stanley zin  a linear programming approach to solving stochastic dynamic programs 1993 postscript       project ideas   the major thrust of the seminar will be to undertake a group project exploring some facet of the problem of planning under uncertainty some sample project ideas are    are there methods of efficiently evaluating plans in complex domains  do mdp aggregation methods have anything to offer  can hierarchical methods be applied to propositional state spaces   can blum and fursts graphplan algorithm be extended to stochastic domains  how do the known results concerning the use of function approximation in dynamic programming relate to one another  how does boutilier and deardens structured policy iteration algorithm perform on some simple structured mdps   were starting to make some progress on a domain for later project development  stephen majercik has written up his ideas on a load balancing mdp which are accessible from his home page     weve talked about using the gala system as a basis for a general declarative language for specifying mdps another options is a standard proposed by rich sutton        last modified thu nov  7 143249 est 1996 by michael littman mlittmancsdukeedu    
